

decided- start with LLM part so can experiment with if working by manually inputting webpage content first. Only then can explore writing parser for the original website articles to extract them automatically

LLM options -
  - open router : 50 searches per day free from common models. Some issues reported with worse quality outputs than going to source, but cheap. If spend $10 can get unlocked 1000 requests per day free from then onward
  - deepseek : very cheap costs per search and good reported performance on STEM benchmarks
  - local LLama / Ollama : no cost and full control and privacy. For models, GPT-OSS 20b  is a promising option (or Qwen3-30B-A3B but that would need more compute resources), though will still be slow on my laptop, and may be confusing to get all the 'hookups' right since will need the tools to call internet searches

 