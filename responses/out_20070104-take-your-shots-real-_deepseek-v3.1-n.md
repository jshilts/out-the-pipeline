
https://www.science.org/content/blog-post/take-your-shots-real-time
# Take Your Shots (For Real, This Time?) (January 2007)

## 1. SUMMARY

This 2007 article analyzes Nature's failed experiment with open peer review. The journal allowed authors to voluntarily make submitted manuscripts available for online public comments, but only 5% of papers were made available, and those received minimal engagement (just 92 comments total across 71 papers, with most papers receiving none). The author argues that the experiment's failure stemmed primarily from **lack of anonymity**. Traditional peer review works because anonymous referees can provide honest, critical feedback without fear of retaliation from authors. The author notes that reviewers like himself often give blunt assessments (including rejections and criticism of citation practices) that they wouldn't feel comfortable making if their identities were known to authors. He suggests that both reviewers and authors would be reluctant to participate in an open system—reviewers wouldn't provide candid feedback, and even fewer authors than the 5% would subject their work to public criticism if reviewers weren't anonymous.

## 2. HISTORY

Open peer review did not disappear after Nature's 2006 experiment. Over the subsequent 18 years, the scholarly publishing landscape evolved significantly:

**Platforms and Journals:**
- **PLOS ONE** (launched 2006) embraced a different model: publish first, peer review focused on technical soundness rather than impact. By 2010, it became the world's largest journal by volume. While not "open review" in Nature's sense, it reduced gatekeeping and democratized publication.
- **F1000Research** (launched 2012) implemented true open peer review with reviewer names and reports published alongside articles, becoming a major platform for life sciences.
- **eLife** (launched 2012) pioneered transparent peer review where reviewer reports (with optional anonymity) were published alongside accepted papers.
- **BMJ** and **BMC** journals adopted various forms of open peer review, some publishing reviewer names.
- **arXiv** (founded 1991) continued as a preprint server with community discussion, though not formal open peer review.
- **bioRxiv** (launched 2013) and **medRxiv** (launched 2019) exploded in usage, becoming standard practice for sharing preprints.

**Adoption Patterns:**
Most major journals (Nature, Science, Cell) did not adopt mandatory open review. Traditional anonymous peer review remained dominant. However, transparent peer review (publishing review reports post-acceptance) gained traction at selective journals. Preprint servers like bioRxiv experienced massive adoption, creating a de facto open review system where anyone can comment publicly.

**Impact on Science:**
- No major regulatory or policy changes mandated open peer review
- The core concern raised—that non-anonymous review would inhibit candid feedback—persisted as a barrier to widespread adoption
- Preprints dramatically accelerated information sharing, particularly during COVID-19
- Concerns about quality control and misinformation on preprint servers paralleled the original anonymity concerns

## 3. PREDICTIONS

- **Prediction: "Many more comments would have come in during Nature's experiment if people had the ability to use anonymous screen names"**
  - **Outcome:** Mixed. Preprint servers like bioRxiv and arXiv do allow anonymous commenting, and while engagement occurs, most papers still receive few comments. The power-law distribution the author noted (few papers getting most attention) persisted across all platforms.
  
- **Prediction: "How many authors would have willingly offered up their papers to such a process? Probably far fewer than the 5% who tried system as it was"**
  - **Outcome:** Partial. For formal open review, this remained true—most authors preferred traditional review. However, voluntary preprint posting exploded with bioRxiv/medRxiv, showing authors *were* willing to expose work to public commentary when it didn't affect publication decisions.
  
- **Implicit prediction: Non-anonymous peer review would fail to gain traction**
  - **Outcome:** Confirmed. Major journals maintained anonymous peer review as default. Even platforms offering open review often provided anonymity options, recognizing author/reviewer reluctance.


## 4. INTEREST

Rating: **7/10**

This article correctly identified the critical barrier to open peer review adoption (anonymity concerns) and its analysis remains relevant today as preprint servers and transparent review continue evolving. While it could not predict the rise of preprint culture, its insights explain why traditional peer review remains dominant alongside newer open models.


----
_model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20070104-take-your-shots-real-time.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_