
https://www.science.org/content/blog-post/thoughts-reproducibility
# Thoughts on Reproducibility (August 2017)

## 1. SUMMARY

Derek Lowe's article addresses the "reproducibility crisis" in scientific research, explaining that unreliable published results are not a new phenomenon but rather a persistent feature of the scientific enterprise. The author categorizes the scientific literature into three tiers: low-quality "junk journals" containing sloppy work and occasional fraud that rarely gets attention; a solid middle stratum (like JOC for organic chemistry) publishing reliable, reproducible work that forms the bulk of scientific research; and top-tier multidisciplinary journals (Science, Nature, JACS) where reproducibility problems re-emerge due to intense publication pressure and the rush to publish high-impact, cutting-edge findings before they are fully validated.

The article argues that while fraud exists at both ends, low-end fraud causes little damage due to lack of attention, while high-end fraud (like the Obokata stem cell case or Schön physics scandal) gets exposed quickly because many researchers attempt to build on important results. The built-in error-correcting mechanisms of science eventually address most problematic findings, though this process can be frustrating for researchers who must spend time debunking unreliable work.

## 2. HISTORY

The reproducibility crisis discussion that Lowe engaged with in 2017 has evolved significantly, though many core issues persist. Major developments include:

**Institutional Responses**: The period after 2017 saw increased institutional efforts to address reproducibility. The FDA began implementing stricter requirements for data transparency in drug approvals, and organizations like the Center for Open Science expanded their reproducibility initiatives. Several major pharmaceutical companies established internal reproducibility committees and began requiring replication studies before advancing drug candidates.

**Continuing Failures**: High-profile failures continued. In 2018-2021, multiple cancer research papers from prestigious institutions faced retractions when replication attempts failed. The biotech sector saw several clinical trial failures attributed to poor preclinical reproducibility, including high-profile Alzheimer's drug candidates that showed promise in animal models but failed in human trials.

**Structural Changes**: Many journals implemented stricter data availability requirements between 2018-2023. Nature, Science, and other major journals now typically require raw data deposition and statistical review. Some fields, particularly genomics and clinical trials, have seen improved reproducibility through mandated data sharing policies.

**Business Impact**: The biotech industry increasingly recognizes that poor preclinical reproducibility carries substantial financial costs. Companies like Amgen and Bayer reported in the early 2020s that they were spending significant resources on replication studies before investing in drug development, acknowledging that 50-60% of published findings in some therapeutic areas couldn't be reproduced.

**COVID-19 Acceleration**: The pandemic highlighted both the importance and difficulty of reproducible science. Initial studies on COVID-19 treatments and mechanisms faced intense scrutiny, with many early findings not holding up. This accelerated adoption of preprint servers and open peer review, but also demonstrated how publication pressure in crisis situations can worsen reproducibility problems.

## 3. PREDICTIONS

The article made several implicit predictions about reproducibility trends:

• **Prediction**: That top-tier journals would continue publishing unreliable results due to publication pressure and the desire for high-impact findings.
  - **Outcome**: This has largely held true. Studies in 2020-2023 showed that retraction rates remain higher in top-tier multidisciplinary journals compared to solid middle-tier field-specific journals, and publication pressure has arguably increased with metrics-driven academic evaluation.

• **Prediction**: That fraud would remain rare at the high end due to rapid exposure when many researchers attempt to replicate important findings.
  - **Outcome**: This prediction has been mostly accurate. Major fraud cases like the COVID-19-related retractions quickly became public, though the damage from brief periods of unreliable high-impact publications remains substantial (affecting research directions, clinical trials, and sometimes policy).

• **Prediction**: That low-end journals would continue publishing low-quality work that causes little harm due to lack of attention.
  - **Outcome**: Correct. The "junk journal" problem persists, with predatory publishers continuing to exploit researchers needing publications. However, citation analysis shows these papers rarely influence subsequent research.

• **Prediction**: That the scientific enterprise's error-correcting mechanisms would continue working effectively overall.
  - **Outcome**: Partially correct. Self-correction works but remains slow and inefficient. Studies suggest it takes 2-4 years on average for problematic findings to be identified and corrected, during which time substantial research resources may be wasted.

• **Implicit assumption**: That reproducibility problems wouldn't fundamentally threaten the scientific enterprise.
  - **Outcome**: This has proven correct in that science continues, but the costs are increasingly recognized. The biotech/pharma sector now budgets significant amounts for replication failures, and some areas like social psychology have implemented sweeping reforms to improve reliability.

## 4. INTEREST

Rating: **7/10**

The article addresses a persistent and important problem in scientific research with nuance and historical perspective, providing valuable insight into the structural causes of reproducibility issues. While the specific analysis is focused on 2017, the framework and observations remain relevant to ongoing discussions about scientific reliability and research quality.


----
_model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20170809-thoughts-reproducibility.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_