model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20141001-no-they-really-aren-t-reproducible.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}}

# Hindsight Analysis: "No, They Really Aren't Reproducible" (2014)

## 1. SUMMARY

This 2014 blog post by Derek Lowe addresses the reproducibility crisis in biomedical research, specifically responding to comments by Nobel laureate Randy Schekman about drug companies' claims that they cannot reproduce published scientific results. Lowe argues from his pharmaceutical industry perspective that when drug companies say results aren't reproducible, they genuinely mean they've attempted to replicate exact experimental conditions but still cannot reproduce the findings. He makes a crucial distinction between two problems: (1) pure irreproducibility where experiments cannot be replicated even when following the published methods exactly, and (2) results that are reproducible but scientifically flawed—for example, assays that work but use compounds that are nonspecific or irrelevant for drug development.

Lowe criticizes the proposed approach of testing the 50 most-cited papers in cancer biology, arguing these papers are highly cited precisely because they're generally reliable. Instead, he suggests targeting more recent "splashy" publications from high-profile journals (Nature, Cell, Science, PNAS) that generate significant press coverage but haven't stood the test of time. He notes that the interview revealed the actual study would focus on "50 most impactful" papers from 2010-2012, which he considers a more appropriate target.

## 2. HISTORY

The Reproducibility Project: Cancer Biology that Lowe referenced launched in 2013 and published its results between 2017-2021. The project attempted to replicate key experiments from 53 high-impact cancer biology papers. The sobering results: only about 46% of the studies were successfully replicated, with effect sizes in replicated studies often being much smaller than originally reported. Many experiments couldn't be completed due to insufficient methodological detail in the original papers.

During this same period (2015-2020), broader reproducibility concerns exploded across science. Psychology faced its own replication crisis, with the Open Science Collaboration's 2015 study showing only 36% of psychological studies could be replicated. The issue gained such prominence that in 2016, Nature surveyed 1,500 scientists, revealing that 70% had tried and failed to reproduce other scientists' experiments, and over 50% had failed to reproduce their own work.

The biotech and pharmaceutical industries responded by becoming increasingly skeptical of academic publications. Companies began investing more heavily in internal validation and requiring multiple independent confirmations before pursuing targets. The crisis also catalyzed the open science movement, leading to greater emphasis on pre-registration of studies, sharing of raw data, and improved methodological reporting standards.

By 2020-2023, journals implemented stricter requirements for data availability and methods description. However, fundamental reproducibility problems persist, particularly in complex biological systems where small variations in cell lines, reagents, or environmental conditions can dramatically affect outcomes.

## 3. PREDICTIONS

**What Lowe got right:**
- His core prediction that reproducibility problems were real and widespread was validated by subsequent studies
- He correctly anticipated that "splashy" papers in high-profile journals would be particularly problematic—later research confirmed that studies with positive, novel findings and extensive press coverage had worse replication rates
- His distinction between purely irreproducible results versus reproducible but flawed science proved prescient; many studies can be reproduced but don't hold up under more rigorous scrutiny
- His skepticism about the pharmaceutical industry being unfairly blamed was vindicated; subsequent revelations showed widespread irreproducibility across academia

**What was more nuanced than predicted:**
- The original Reproducibility Project (testing 50 most-cited papers) turned out to be more valuable than Lowe initially suggested, as it revealed significant problems even in foundational, highly-cited work
- The scope of the crisis proved broader than just recent flashy papers; established "gold standard" findings also showed reproducibility issues
- The solutions proved more challenging than anticipated; while awareness increased dramatically, structural incentives (publish-or-perish culture, emphasis on novelty over robustness) remained largely unchanged

## 4. INTEREST

**Decile Score: 8/9**

This article ranks in the 8th decile (80-89th percentile) for long-term importance and interest. While written as a blog post rather than formal research, it captured a pivotal moment in scientific self-examination. The reproducibility crisis has had profound implications:

- **Scientific credibility**: The crisis forced a reckoning with quality standards across biomedicine
- **Economic impact**: Wasted R&D resources due to pursuing irreproducible findings likely cost billions
- **Policy changes**: Led to major funding agency requirements for data sharing and reproducibility
- **Cultural shift**: Sparked broader discussions about research integrity and scientific incentives

However, it falls short of the absolute highest tier (9/9) because the core insights were part of a broader conversation already underway, and while influential, it was one voice among many driving this change. The ultimate solutions remain incomplete, making this more of a critical diagnostic piece than a transformative solution.

The article's value lies in its insider perspective and accurate diagnosis of where the most serious problems were concentrated—insights that proved remarkably prescient over the following decade.