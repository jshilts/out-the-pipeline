
https://www.science.org/content/blog-post/reproducibility-initiative-open
# The Reproducibility Initiative is Open (October 2013)

## 1. SUMMARY

The article discusses the launch of the Reproducibility Initiative, which received a $1.3 million grant from the Center for Open Science to validate high-profile results in oncology research literature. The initiative planned to reproduce approximately 50 key papers through the Science Exchange platform, with all results made freely available to the public. The author expresses cautious optimism about the project while questioning whether the funding would be sufficient to complete all the proposed replication studies, noting that some oncology experiments are expensive and time-consuming. The article frames this as an important step toward establishing reproducibility validation as a real-world practice in scientific research.

## 2. HISTORY

The Reproducibility Initiative evolved significantly after 2013, though not necessarily along the exact trajectory initially envisioned:

The Center for Open Science continued to expand its reproducibility efforts beyond oncology, launching large-scale replication projects across multiple disciplines. Perhaps most notably, the **Reproducibility Project: Cancer Biology** began in 2013-2014 and eventually published results attempting to replicate key findings from high-impact cancer papers. The project struggled with the very funding and logistical challenges the article anticipated - replication studies proved more expensive and complex than original estimates suggested.

Starting around 2014-2015, major pharmaceutical companies (including Bayer and Amgen) published analyses showing that they could only reproduce about 20-25% of published academic findings when attempting drug development. This contributed to broader recognition of reproducibility problems in biomedical research.

The initiative's platform, Science Exchange, continued operating as a marketplace for outsourcing scientific research services. However, large-scale systematic replication of 50 oncology papers faced considerable challenges - many replication attempts revealed discrepancies, while others couldn't be completed due to insufficient methodological detail in original papers or lack of cooperation from original authors.

By 2016-2018, the conversation around reproducibility had expanded significantly, with major journals implementing new standards for data sharing, preregistration of studies, and more detailed methods sections. While this represented progress, the ambitious goal of systematically validating 50 key oncology papers proved more difficult than initially hoped.

## 3. PREDICTIONS

- **Prediction that $1.3 million wouldn't be enough for 50 papers**: This proved accurate. Replication studies, particularly in oncology involving animal models, cell culture work, and specialized assays, often cost $30,000-$100,000+ each when done properly. The initiative likely needed 3-5 times the initial funding for comprehensive replication of 50 papers.

- **Hope that this would establish reproducibility validation as common practice**: This had mixed outcomes. The initiative did raise awareness and contributed to cultural changes in science, with more journals requiring data availability and better methods reporting. However, systematic third-party replication never became standard practice - it remains relatively rare compared to the scale of published research.

- **Expectation that careful target selection would make the money sufficient**: This underestimated the complexity. Even "carefully selected" papers presented challenges - missing raw data, incomplete methods, unavailable reagents, and unwillingness of original authors to share protocols made many replication attempts impossible regardless of funding.

## 4. INTEREST

**Rating: 7/10**

This article captures a pivotal moment when the scientific community began systematically confronting reproducibility problems. While the specific initiative faced challenges, it was part of a broader movement that fundamentally changed how science is conducted and published, making this historically significant despite the initiative's mixed practical success.


----
_model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20131017-reproducibility-initiative-open.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_