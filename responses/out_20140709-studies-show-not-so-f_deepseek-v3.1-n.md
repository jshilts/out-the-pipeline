
https://www.science.org/content/blog-post/studies-show-not-so-fast
# Studies Show? Not So Fast. (July 2014)

## 1. SUMMARY

This commentary critiques the reliability of observational studies, particularly those generating medical headlines about associations between lifestyle factors and health outcomes (e.g., "eating broccoli is associated with X"). The author argues that such studies typically produce spurious correlations rather than causal insights, contrasting them with randomized controlled trials (RCTs) that are methodologically superior but harder to conduct. 

The article references a 2011 paper by Young and Karr which systematically reviewed instances where observational findings were later tested in RCTs, finding a "horrendous" track record of non-replication. These authors concluded that "any claim coming from an observational study is most likely to be wrong." The piece also discusses the manufacturing analogy proposed by Young and Karr: scientific publishing lacks process control, with journal editors and referees only inspecting final products rather than ensuring quality at each step. The article advocates for a rigorous seven-step process control framework that would separate data collection from analysis, pre-specify protocols, use hold-out validation datasets, and make results (including validation outcomes) public before publication decisions.

## 2. HISTORY

Subsequent developments following this 2014 article confirmed and amplified the core concerns about observational studies:

**The Reproducibility Crisis Recognition (2015-2016):** The scientific community increasingly acknowledged widespread problems with research reliability. Large-scale replication efforts in psychology and other fields documented shockingly low reproducibility rates, validating the article's skepticism about published findings.

**p-Hacking and HARKing Exposures:** During 2014-2018, documented practices like p-hacking (manipulating analyses to achieve statistical significance) and HARKing (hypothesizing after results are known) became widely discussed problems that explained why observational studies so often failed to replicate.

**Increased Pre-registration Adoption:** The solution advocated in the article (pre-specifying analysis plans) gained substantial traction through preregistration platforms like the Open Science Framework (launched 2013 but adoption accelerated post-2015). By 2020-2022, thousands of studies were being preregistered annually, representing concrete progress toward the process control the article advocated.

**FDA and Regulatory Changes:** The 21st Century Cures Act (2016) and FDA initiatives increasingly emphasized real-world evidence but maintained rigorous standards. While some policy discussions explored using observational data for regulatory decisions, actual approvals continued requiring controlled trials for most interventions, confirming the article's implicit hierarchy of evidence.

**COVID-19 Pandemic Validation (2020-2021):** The pandemic provided a real-time case study. Many early observational claims (e.g., hydroxychloroquine effectiveness, various drug associations) failed spectacularly when tested in RCTs like the WHO Solidarity trial. The public witnessed firsthand the reliability gap the 2014 article described.

**Business Impact - Cochrane and Meta-Analysis Standardization:** Systematic review organizations and meta-analytic approaches gained prominence, with funding increasingly directed toward methodological rigor. Pharmaceutical companies invested more heavily in high-quality RCT infrastructure, though observational pharmacovigilance studies remain problematic.

## 3. PREDICTIONS

The article's central prediction was **implicit rather than explicit**: that continuing the status quo would perpetuate unreliable science. The evaluation is mixed:

• **Process control adoption**: Young and Karr's proposed seven-step framework did NOT become the universal standard; however, key elements gained traction through preregistration movements. The prediction that "we would all be better off" if such protocols were normative proved directionally correct, though implementation remains incomplete a decade later.

• **The broccoli/chocolate/headstanding examples**: The pattern the article identified continued relentlessly - observational nutrition studies generating headlines followed by non-replication persisted throughout 2014-2024. The prediction that this cycle would continue absent methodological reform proved entirely accurate.

• **Consumer education limitations**: The article predicted that "no amount of educating the consumer will fix the process." This proved prescient - despite increased science communication efforts, media coverage of dubious observational associations continued, and public confusion about contradictory health advice persisted through 2024.

• **Journal peer review inadequacy**: The critique that peer review only inspects final products while missing underlying methodological flaws became widely accepted. However, the prediction that this would remain unchanged proved too pessimistic - some journals began requiring preregistration and data sharing post-2016.

## 4. INTEREST

Rating: **8/10**

This article identified a fundamental problem in scientific publishing that became central to the reproducibility crisis discussions of 2015-2020. Its relevance extended far beyond biotech to affect policy decisions, research funding allocation, and public trust in science during the COVID-19 pandemic, making it more consequential than typical industry commentary.


----
_model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20140709-studies-show-not-so-fast.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_