
https://www.science.org/content/blog-post/publication-bias
# Publication Bias (July 2015)

## 1. SUMMARY

This commentary argues that the reproducibility crisis in scientific research cannot be solved by replication studies alone because the root problem is systematic publication bias—the tendency to only publish positive or statistically significant results. The author notes that most experiments in both industry and academia never get published, particularly negative results and failed attempts. While pharmaceutical companies face criticism for not publishing negative compound results, academic researchers also selectively publish due to career pressures like grant renewals and tenure decisions. The article suggests that without addressing publication bias directly, even well-intentioned replication efforts may further obscure rather than clarify the scientific record, and emphasizes that only well-powered, statistically rigorous studies can produce credible results, though they are more expensive and time-consuming to conduct.

## 2. HISTORY

In the years following this 2015 article, publication bias and research reproducibility became increasingly recognized as critical issues in scientific research:

**Clinical Trial Transparency**: The movement for clinical trial registration and results disclosure gained significant momentum. Regulatory requirements strengthened, with both the FDA and EMA expanding mandates for trial registration and public reporting of results, reducing the problem of unpublished negative pharmaceutical trials mentioned in the article.

**Reproducibility Initiatives**: Large-scale replication projects continued and expanded, including the Reproducibility Project: Cancer Biology (launched 2013, ongoing through 2021) and various psychology replication efforts. These studies consistently found replication rates between 36-77% depending on the field, validating concerns about reproducibility but also showing that replication studies themselves faced publication challenges.

**Pre-registration Growth**: The practice of pre-registering studies, particularly in clinical research and psychology, became more widespread. Platforms like ClinicalTrials.gov and the Open Science Framework's preregistration system gained substantial adoption, addressing the publication bias problem by committing to publish results regardless of outcome.

**Journal Policy Changes**: Many journals adopted policies requiring data sharing, pre-registration, or commitment to publishing negative results. Some journals specifically dedicated to negative results emerged, though with mixed success in terms of impact and sustainability.

**Meta-Research Expansion**: The field studying research practices (meta-research) grew substantially between 2015-2020, with numerous high-profile papers examining publication bias, statistical power, and research practices across disciplines. This research consistently confirmed that publication bias remains widespread.

**Industry Impact**: Pharmaceutical and biotechnology companies increasingly adopted systematic review and meta-analysis approaches, and some companies made commitments to greater transparency in publishing all trial results, though implementation remained uneven across the industry.

The core concerns raised in 2015 remained relevant throughout this period, with progress being made more in clinical research transparency than in addressing fundamental publication bias across all scientific disciplines.

## 3. PREDICTIONS

The article contained several explicit and implicit predictions:

• **"Replication studies will have publication bias, too - at the moment, they're hot, but that won't always be the case."**
  - **Outcome**: This prediction proved largely accurate. While replication studies maintained momentum through 2020, particularly in high-profile projects, they did face their own publication challenges. Replication studies with "negative" results (failing to replicate) sometimes struggled for publication, and interest in funding large-scale replication efforts varied over time, though the reproducibility movement maintained stronger momentum than the article anticipated.

• **Implicit prediction that publication bias would persist without systematic changes**
  - **Outcome**: **Accurate**. Meta-analyses published 2016-2023 continued to demonstrate significant publication bias across multiple fields. Despite increased awareness and some policy changes, fundamental incentives around publication, career advancement, and funding continued to favor positive results. The problem proved more entrenched than optimists hoped.

• **Prediction that only well-powered, statistically rigorous studies could produce believable results**
  - **Outcome**: **Partially accurate but incomplete**. While statistical rigor remained crucial, the solution proved more complex. The research community increasingly recognized that effect sizes, confidence intervals, and pre-registration were as important as statistical power alone. The emphasis shifted toward methodological transparency and pre-registration rather than simply requiring larger sample sizes.

## 4. INTEREST

Rating: **7/10**

This article identified publication bias as a fundamental constraint on scientific self-correction—a systemic issue that remained highly relevant and largely unresolved for years after publication. The insight that replication alone cannot solve reproducibility when bias remains systematic was prescient and increasingly validated.


----
_model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20150721-publication-bias.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_