
https://www.science.org/content/blog-post/our-most-snorted-at-papers-month
# Our Most Snorted-At Papers This Month. . . (November 2014)

## 1. SUMMARY

The article discusses how scientific papers with egregious errors or methodological flaws—those that researchers commonly mock or criticize—can paradoxically drive high traffic to journal websites. The author notes that such papers may dominate journals' "Most viewed" or "Most shared" metrics systems, inadvertently skewing the perceived impact and quality assessments of these publications. The piece references a blog post by Neil Saunders that explores the challenges of measuring research quality, including examples of papers that likely achieved high visibility precisely because of their notoriety rather than scientific merit.

## 2. HISTORY

The phenomenon described in this 2014 article reflects ongoing tensions in academic publishing that have only intensified with digital platforms. Scientific and medical publishing have continued struggling with balancing traditional impact metrics against the reality of attention economics. In subsequent years:

- Altmetric.com and similar platforms expanded tracking of article-level metrics beyond citation counts to include social media mentions, news coverage, and online attention, though these don't fully distinguish between celebratory and critical attention.
- Several prominent retractions of widely-covered "snorted-at" papers occurred, such as the STAP cell controversy in Nature (2014), which attracted massive attention before retraction.
- The replication crisis deepened awareness that highly-cited or media-covered research wasn't always methodologically sound.
- Publishers introduced clearer correction/retraction notices and some experimentation with post-publication review, yet journal homepage "most-viewed" listings remained largely driven by raw traffic rather than quality assessment.
- Social media platforms amplified both rapid dissemination of bad science and public mockery of flawed studies, creating a feedback loop where serious research might receive less attention than controversial studies, even when the outcome was a failed replication or retraction.

## 3. PREDICTIONS

No explicit predictions were made in this article—it was observational commentary rather than forecasting future developments.

## 4. INTEREST

**Score: 3**

While the article identifies a real and persistent problem in academic publishing metrics, it's primarily a commentary piece rather than original analysis of scientific developments or biotechnology. The metacognitive issue about research quality measurement remains relevant, but this is relatively narrow and more of a publishing industry concern than a major biotechnology breakthrough or failure.


----
_model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20141113-our-most-snorted-at-papers-month.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_