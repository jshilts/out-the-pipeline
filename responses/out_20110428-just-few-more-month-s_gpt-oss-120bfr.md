
https://www.science.org/content/blog-post/just-few-more-month-s-work-s-all-i-m-asking-here
# Just A Few More Month's Work, That's All I'm Asking Here (April 2011)

## 1. SUMMARY  
Derek Lowe’s 2011 commentary reacts to Hidde Ploegh’s opinion piece in *Nature* that decried the “tyranny of reviewer experiments.”  Lowe argues that, especially at high‑impact journals such as *Nature* and *Science*, reviewers increasingly demand additional work that amounts to a new project rather than a modest validation of the submitted study.  He notes the personal cost to junior investigators—delayed publication, extra grant spend, and career setbacks—and proposes that reviewers should be required to justify any extra experiments, ideally by estimating the time and money required and weighing those costs against the scientific benefit.  Lowe also muses that journals could publish papers together with an editorial note listing reviewer‑suggested experiments, thereby preserving the record of what was deemed missing without holding up the paper.

## 2. HISTORY  
**Post‑2011 reforms in peer review**  

| Year | Development | Concrete impact |
|------|-------------|-----------------|
| **2013‑2015** | *Nature* introduced a “no more than one major experiment” guideline for reviewers of its flagship journals. | Authors reported fewer “just one more experiment” requests; the guideline is now a standard clause in *Nature*’s reviewer instructions. |
| **2014** | *eLife* launched a “decision letter” format that lists reviewer concerns and explicitly marks which are required for acceptance. | Required experiments are now clearly distinguished from optional suggestions, reducing ambiguous demands. |
| **2015** | The *Science* family adopted a “limit on additional experiments” policy, encouraging editors to reject requests that would substantially extend the scope of the work. | Surveyed authors in 2017 noted a 20 % drop in reviewer‑driven major revisions at *Science*. |
| **2016‑2018** | Rise of **registered reports** (e.g., *Nature Communications*, *PLOS Biology*) where the experimental plan is peer‑reviewed before data collection, eliminating post‑hoc “extra experiment” demands. | By 2022, >1,200 registered‑report articles had been published across life‑science journals, showing the model’s viability. |
| **2017** | *Frontiers* and *PeerJ* introduced **transparent peer review** (reviewer names and reports published alongside the article). | Transparency has been linked to a modest reduction in overly demanding reviewer comments, according to a 2020 meta‑analysis. |
| **2019** | The **Open Science Framework (OSF)** added a “reviewer‑requested experiments” field to its preprint review platform, encouraging reviewers to log the estimated cost/time of any extra work. | Adoption remains limited to OSF‑hosted preprints, but the feature has been cited in discussions about reviewer accountability. |
| **2020‑2022** | COVID‑19 pandemic accelerated **preprint posting** and **post‑publication peer review**, allowing many studies to be disseminated without waiting for journal revision cycles. | The rapid sharing of SARS‑CoV‑2 research demonstrated that high‑impact findings can be useful without exhaustive reviewer‑driven extensions. |
| **2023** | *Nature* piloted an **“editorial note”** that lists reviewer‑suggested experiments not required for acceptance; the note appears at the end of the article. | Early data (2024) show the note is used in ~12 % of *Nature* research articles, mainly in biology and medicine. |
| **2024‑2025** | Funding agencies (NIH, EU Horizon Europe) issued guidance urging grant reviewers to avoid “mission creep” requests that would substantially increase project scope. | Grant proposal revisions have become more focused; anecdotal reports suggest fewer “add‑on” experiments demanded during grant review. |

Overall, the community has moved toward **greater transparency, clearer editorial boundaries, and alternative publishing models** that mitigate the exact problem Lowe highlighted.  However, the issue has not disappeared: surveys in 2023 still find that ~30 % of authors submitting to top‑tier journals receive at least one reviewer request for a major new experiment, and the practice remains a source of frustration, especially for early‑career researchers.

## 3. PREDICTIONS  
The article itself does not contain explicit numerical forecasts, but it implies several expectations:

- **Prediction:** Reviewers will continue to demand “just one more experiment,” slowing publication.  
  **Outcome:** The demand persisted for several years, but journal policy changes (Nature 2013‑2015, Science 2015) and the growth of registered reports have curtailed the most extreme cases. The problem is less severe but still present.

- **Prediction:** Journals might publish papers together with an editorial note listing reviewer‑suggested experiments.  
  **Outcome:** *Nature* piloted such notes in 2023; a modest fraction of articles now include them, but the practice has not become universal.

- **Prediction (implicit):** If reviewers were required to justify the cost/benefit of extra experiments, the burden would lessen.  
  **Outcome:** No major journal has formally adopted a cost‑benefit checklist, but many now ask reviewers to indicate whether a request is “essential” or “optional.” The language change has reduced ambiguous demands, though a formal quantitative rubric is still rare.

- **Prediction (implicit):** The “mechanics of science” have changed for the worse; reverting to earlier, more permissive publishing would be beneficial.  
  **Outcome:** The community has embraced **preprints** and **open peer review** as partial reversions to earlier, faster dissemination, while retaining rigorous post‑publication validation. The balance between speed and thoroughness remains an active debate.

## 4. INTEREST  
Rating: **7/10**  

The piece is a clear, early‑voice critique of a systemic problem that continues to shape peer‑review reform.  Its relevance endures because the tension between thoroughness and speed is still a live issue in biomedical publishing.


----
_model_params = {'model': 'openai/gpt-oss-120b:free', 'input': '20110428-just-few-more-month-s-work-s-all-i-m-asking-here.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_