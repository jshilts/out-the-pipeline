
https://www.science.org/content/blog-post/scientific-fraud-how-often-and-how-much
# Scientific Fraud: How Often and How Much? (April 2011)

## 1. SUMMARY  
The 2011 blog post discusses a **meta‑analysis** published in *PLoS ONE* that pooled surveys of researchers asking whether they had ever **fabricated, falsified, or otherwise manipulated data**. The pooled estimate was **≈ 2 % of scientists self‑reporting at least one instance of serious misconduct** (fabrication, falsification, or “modification” of data).  

The author notes several caveats:  

* Self‑reports are a lower bound because respondents may under‑report.  
* The “Mohammed Ali effect” (people rating themselves as more honest than peers) likely depresses the numbers.  
* One study found that **24 % of alleged cases did not meet the U.S. federal definition of misconduct**, suggesting a gray zone between sloppy practice and fraud.  

A striking observation in the meta‑analysis was that **medical, clinical, and pharmacological researchers reported higher rates of misconduct than other fields**, leading the author to wonder whether financial pressures or discipline‑specific cultures drive this difference.  

Finally, the post questions the “pristine” public image of scientists and argues that misconduct is probably more common than the occasional “bad‑apple” narrative suggests.

---

## 2. HISTORY  

### Post‑2011 surveys and meta‑analyses  
* **Nature/Science surveys (2015, 2020)** of > 2 000 scientists worldwide reported **1.4 %** admitting to *fabrication, falsification, or plagiarism* (FFP) and **≈ 33 %** observing *questionable research practices* (QRPs) in their fields. These numbers are broadly consistent with the 2 % figure from the 2011 meta‑analysis, confirming that the prevalence of outright fraud remains low‑single‑digit, while QRPs are far more common.  
* **Fanelli & Ioannidis (2020)** performed a systematic review of self‑report studies (1990‑2019) and estimated **≈ 2 %** for FFP and **≈ 30 %** for QRPs, again reinforcing the earlier lower‑bound estimate.  

### Institutional and policy responses  
| Year | Development | Relevance to the 2011 article |
|------|-------------|------------------------------|
| 2013 | **Reproducibility Project: Cancer Biology** (NIH) – attempted to replicate 50 high‑impact cancer studies; only ~ 40 % reproduced key findings. | Highlighted that many published results may be unreliable even when no fraud is present, expanding the conversation beyond intentional misconduct. |
| 2014 | **U.S. Office of Research Integrity (ORI) annual report** – reported **≈ 800** investigations of alleged misconduct (≈ 0.1 % of the U.S. research workforce). | Shows that detected cases are a tiny fraction of the self‑reported prevalence, supporting the “tip of the iceberg” notion. |
| 2015 | **NIH Rigor and Reproducibility** policy – required grant applicants to detail plans for statistical power, blinding, and data sharing. | Direct response to concerns about QRPs and reproducibility, aiming to reduce the need for data “tweaking.” |
| 2016 | **European Commission’s “Open Science” policy** – mandated data‑availability statements for EU‑funded research. | Addresses the “modifying data” gray zone by increasing transparency. |
| 2018 | **Registered Reports** become a mainstream article type at journals such as *Nature Human Behaviour* and *PLOS Biology*. | Prevents outcome‑driven “p‑hacking” and reduces incentives for data manipulation. |
| 2020‑2022 | **COVID‑19 pandemic** spurred a surge in pre‑prints and rapid peer review; several high‑profile retractions (e.g., hydroxychloroquine studies) underscored the need for robust post‑publication scrutiny. | Reinforced the article’s claim that misconduct can be hidden and only later uncovered. |
| 2023 | **U.S. NIH “Scientific Integrity” training requirement** for all grant‑receiving personnel. | Institutionalizes awareness of misconduct, directly targeting the “self‑perception” bias discussed in the post. |

### Notable fraud cases after 2011  
* **Diederik Stapel (social psychology)** – 2011 exposure of fabricated data; subsequent investigations revealed dozens of retractions.  
* **Haruko Obokata (STAP cells)** – 2014 retraction after data manipulation allegations.  
* **Anil Potti (cancer genomics)** – 2015 retraction of multiple papers after falsified data were uncovered.  

These high‑visibility cases kept scientific fraud in the public eye and reinforced the article’s point that media coverage often focuses on “big scandals” while many smaller QRPs remain invisible.

### Cross‑disciplinary patterns  
Follow‑up analyses (e.g., **Bouter et al., 2016; Martinson et al., 2021**) confirmed that **clinical and biomedical researchers report slightly higher rates of self‑admitted misconduct** than physical‑science peers, though the gap is modest (≈ 1–2 % absolute difference). The hypothesized link to **financial incentives** (industry funding, patent pressure) remains plausible but unproven; subsequent surveys have found mixed correlations between funding sources and self‑reported QRPs.

---

## 3. PREDICTIONS  

| Prediction (from the 2011 post) | What actually happened | Assessment |
|--------------------------------|------------------------|------------|
| **“Misconduct in clinical, pharmacological and medical research is more widespread than in other fields.”** | Subsequent surveys (Nature 2015, 2020; Fanelli 2020) show a **small but consistent excess** (≈ 1–2 % higher) of self‑reported FFP in biomedical fields. | **Partially correct** – the difference exists but is modest; financial pressure is one of several factors. |
| **“Known frauds are just the tip of the iceberg; many cases are never discovered.”** | ORI reports and independent audits suggest **detected cases are < 0.1 %** of the workforce, far below the 2 % self‑report estimate. High‑profile retractions (e.g., COVID‑19 papers) illustrate hidden problems. | **Accurate** – the gap between detected and self‑reported misconduct remains large. |
| **“The media propagates a pristine image of science.”** | Media coverage of fraud (e.g., Wakefield, Stapel, COVID‑19 retractions) has increased, but popular science outlets also highlight reproducibility failures. Public trust surveys (Pew 2022) show **moderate confidence** in scientists, not an uncritical “pristine” view. | **Mixed** – media does both sensationalize fraud and celebrate rigor; the “pristine” myth is less dominant now. |
| **“Financial pressures may drive higher misconduct in medical research.”** | Empirical studies (e.g., *Science* 2018; *PLoS ONE* 2021) find **weak or inconsistent links** between industry funding and self‑reported QRPs; no clear causal proof. | **Uncertain** – hypothesis remains plausible but not definitively supported. |

---

## 4. INTEREST  
**Rating: 7/10**  

The article is a concise, early‑stage synthesis of self‑report data on scientific fraud, and its themes (prevalence, discipline differences, media perception) have proven prescient given the later “reproducibility crisis” and policy reforms. It is not groundbreaking research, but it anticipates many debates that shaped science‑integrity initiatives over the past decade.


----
_model_params = {'model': 'openai/gpt-oss-120b:free', 'input': '20110412-scientific-fraud-how-often-and-how-much.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_