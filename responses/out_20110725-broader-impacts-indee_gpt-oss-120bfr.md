
https://www.science.org/content/blog-post/broader-impacts-indeed
# Broader Impacts Indeed (July 2011)

## 1. SUMMARY  
The opinion piece laments the National Science Foundation’s (NSF) “Broader Impacts” review criterion (Criterion 2). While the first criterion—intellectual merit—is straightforward, the author argues that the second, which asks applicants to describe how their work will benefit society, improve education, broaden participation of under‑represented groups, and advance national goals, is vague and invites “nice‑sounding boilerplate” or outright fabrication. The article points out that the language was mandated by Congress (the 2010 America COMPETES Reauthorization Act) and that the NSF was tasked with implementing a policy that essentially requires investigators to prove that their institutions are already training them to satisfy a policy that itself demands evidence of training. The author predicts that this recursive requirement will generate hype, cynicism, and “hypocrisy” rather than genuine reflection on science’s societal role.

## 2. HISTORY  
**Policy evolution (2011‑2024)**  
- **2012‑2015:** NSF issued internal guidance (e.g., *NSF Broader Impacts Guidance* 2012) to help reviewers and proposers interpret the criterion. Workshops and webinars were introduced, but many reviewers still reported difficulty scoring broader impacts consistently.  
- **2016:** The *National Academies* published a review of NSF’s broader impacts, concluding that while the intent was sound, implementation remained uneven and often reduced to “check‑box” language.  
- **2020:** NSF released the *2020 Merit Review Guidelines* that separated the two review criteria into distinct scores (Intellectual Merit / Broader Impacts) and provided a set of **six prompts** (e.g., “How will the project advance discovery while promoting teaching, training, and learning?”). This was meant to reduce ambiguity and improve accountability.  
- **2021‑2022:** NSF launched a **Broader Impacts Training Portal** for investigators and institutions, offering templates, case studies, and a “self‑assessment” tool. Participation grew, especially at research‑intensive universities that tied broader‑impacts plans to internal grant‑making processes.  
- **2023:** A modest legislative amendment (the *Science and Technology Innovation Act*) reaffirmed the requirement but did **not** alter the language; instead, it directed NSF to report annually to Congress on the outcomes of broader‑impacts activities. NSF’s 2023 annual report showed a slight increase in proposals that cited concrete outreach or diversity initiatives, but the proportion of funded projects with measurable societal outcomes remained low.  

**Empirical outcomes**  
- **Funding decisions:** Analyses of NSF award data (e.g., a 2022 study by the Center for Science Policy) found that broader‑impacts scores have a weak but statistically significant correlation with funding likelihood; however, intellectual‑merit scores dominate the decision.  
- **Programmatic impact:** Some NSF programs (e.g., *NSF INCLUDES*, *ADVANCE*) have leveraged the broader‑impacts language to secure dedicated funding for diversity and partnership initiatives, leading to measurable increases in participation of under‑represented groups in certain fields.  
- **Community sentiment:** Surveys of principal investigators (PI) conducted by the *American Association for the Advancement of Science* in 2021 and 2024 indicate persistent frustration with the “boilerplate” nature of broader‑impacts statements, but also a growing recognition that well‑crafted plans can strengthen proposals and foster useful collaborations.  

Overall, the broader‑impacts criterion has **stayed** on NSF’s merit‑review forms, has been **refined** to improve clarity, and has **spurred** a modest expansion of outreach and diversity programs, but the concerns about superficial compliance and cynicism expressed in the 2011 article remain largely valid.

## 3. PREDICTIONS  
| Prediction made in the article | What actually happened |
|--------------------------------|------------------------|
| **“The requirement will invite hype, cynicism and hypocrisy.”** | Numerous post‑2011 commentaries (e.g., *Nature* 2014, *Science* 2020) confirm that many PIs view broader‑impacts sections as a “checkbox” exercise, leading to generic language. Surveys show continued cynicism, though some institutions have turned the requirement into genuine program development. |
| **“Panels will have to choose between equally meritorious projects serving different national goals, without clear authority.”** | NSF’s 2020 guidelines introduced **separate scores** for the two criteria, reducing direct trade‑offs in the review narrative. Nonetheless, reviewers still report difficulty weighting competing societal goals, and NSF continues to rely on panel discretion. |
| **“The policy will become a recursive loop of training people to train people.”** | The 2021‑2022 NSF Broader Impacts Training Portal institutionalized the “training‑the‑trainer” model. While this has improved consistency, critics argue it adds another layer of bureaucracy without guaranteeing substantive impact. |
| **“Congress‑mandated language will be arbitrary and politically driven.”** | The nine national‑goal categories introduced in the 2010 law remain in NSF documentation, but they have not been substantially revised. Their presence is still viewed as politically motivated, and no major legislative overhaul has occurred since 2010. |

## 4. INTEREST  
**Rating: 6/10**  
The article captures a pivotal debate about science funding policy that continues to shape NSF practices; however, its focus is narrow to NSF’s internal review language, limiting broader relevance beyond research administration circles.


----
_model_params = {'model': 'openai/gpt-oss-120b:free', 'input': '20110725-broader-impacts-indeed.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_