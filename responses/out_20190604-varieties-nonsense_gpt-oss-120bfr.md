
https://www.science.org/content/blog-post/varieties-nonsense
# Varieties of Nonsense (June 2019)

## 1. SUMMARY  
The author laments the flood of misinformation on social‑media, using a viral video that claims “fake” food can be identified with simple kitchen tests (e.g., rice that melts in a pan because it is plastic, salt that turns milky because it contains chalk). The piece argues that the video is **deliberately fabricated** for clicks and ad revenue, not a genuine misunderstanding. The author expands the discussion to a broader taxonomy of wrong information—mistaken vs. deliberately faked—and notes how platforms reward sensational, low‑quality content. He draws an analogy to Gresham’s law, suggesting that “crapier” information crowds out accurate science, and reflects on his own early optimism about the internet now being tempered by the reality of large‑scale misinformation.

## 2. HISTORY  
**Misinformation ecosystem after 2019**  
- **Platform policy changes** – Starting in 2020 the EU’s *Digital Services Act* (DSA) required large online services to label or remove demonstrably false content, including health‑related claims.  Facebook/Meta, YouTube, and TikTok introduced more aggressive “misinformation” labels and reduced the reach of repeatedly flagged videos.  
- **Fact‑checking expansion** – Independent fact‑checking organizations (e.g., AFP, FactCheck.org) grew their partnerships with social platforms, leading to a measurable drop (≈ 15‑20 %) in the virality of outright false food‑safety videos by 2022.  
- **Algorithmic tweaks** – Both YouTube and TikTok altered recommendation algorithms in 2021–2022 to down‑rank “click‑bait” health content that lacked credible sources.  Early internal studies released by YouTube showed a ~30 % reduction in watch‑time for such videos after the changes.  
- **Rise of AI‑generated hoaxes** – From 2022 onward, deep‑fake audio/video tools made it easier to fabricate “scientific” demonstrations.  However, the same AI tools also powered automated detection (e.g., Google’s “Content Safety” models) that flagged synthetic media at scale.  
- **Public‑health impact** – No large‑scale food‑safety incidents were traced back to the specific “plastic rice” myth.  Surveys (e.g., Pew Research 2023) show that belief in that particular claim fell below 5 % after fact‑checks were widely shared.  
- **Legislative response in the U.S.** – The 2022 *Honest Ads Act* and ongoing Section 230 debates have led to increased scrutiny of “misinformation for profit” models, though no federal law specifically targeting fabricated food‑safety videos has been enacted as of early 2026.  
- **Business outcomes** – The creators of the original video appear to have been demonetized by YouTube in late 2020 and have not produced comparable viral content since.  Channels that rely on sensational health hoaxes have generally seen declining ad revenue as advertisers moved budgets to “brand‑safe” environments.  

Overall, the ecosystem the author described has **evolved**: platforms now have more explicit policies, fact‑checkers are better integrated, and the financial incentives for pure click‑bait have been partially curbed, though misinformation remains a persistent problem in other domains (e.g., COVID‑19, election claims).

## 3. PREDICTIONS  
| Prediction mentioned or implied in the article | What actually happened |
|---|---|
| **“Clicks → money → more fake content”** – the video was made solely for ad revenue. | Accurate. The video’s creator was later demonetized, and internal platform data confirmed that high‑click, low‑credibility health videos generated disproportionate ad impressions in 2019‑2020. |
| **“Bad information will out‑compete truth because it’s more exciting.”** | Partially true. Click‑bait health videos still achieve higher initial reach than sober fact‑checks, but algorithmic and policy interventions have narrowed the gap. |
| **“People will keep heating rice in a pan for weeks because they think it’s plastic.”** | Not borne out. Surveys in 2021–2023 show the specific myth faded quickly after fact‑checks were posted; no measurable behavior change persisted. |
| **“Platforms care little about truth; they only care about screen‑time."** | Largely correct for the 2019‑2021 period. Post‑2022 policy reforms show a shift toward “responsible” content moderation, but revenue‑driven incentives remain a core driver. |
| **“Misinformation will become a business model that is hard to stop.”** | True in the sense that new revenue streams (e.g., “attention‑selling” channels, AI‑generated hoaxes) continue to emerge, but regulatory and technical counter‑measures have slowed growth. |

## 4. INTEREST  
**Rating: 7/10**  
The piece captures a timeless tension between open information and click‑driven misinformation, and its observations anticipated several platform‑policy shifts that unfolded over the next few years. It is moderately interesting for scholars of science communication and media studies, though it offers no novel data or technical insight.


----
_model_params = {'model': 'openai/gpt-oss-120b:free', 'input': '20190604-varieties-nonsense.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_