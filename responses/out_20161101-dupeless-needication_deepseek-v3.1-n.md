
https://www.science.org/content/blog-post/dupeless-needication
# Dupeless Needication (November 2016)

## 1. SUMMARY

This 2016 commentary discusses the discovery of duplicated images in two research papers from the same group at the University of Malaya. The author identifies that Figure 4 from a 2014 paper in *The Scientific World Journal* is identical to Figure 2 from a later 2015 paper in *Scientific Reports*, despite the papers supposedly examining different compounds. The article criticizes this as fraudulent research and questions why journal editors don't use image-comparison software to automatically detect such duplications across papers. The author expresses concern that as machine learning systems trawl scientific literature for insights, they'll inadvertently incorporate such fabricated data, and suggests the scientific community needs to clean up the literature before attempting large-scale knowledge integration.

## 2. HISTORY

In the years following this 2016 article, automated image forensics did gradually emerge. By the late 2010s and early 2020s, several commercial and open-source tools became available for detecting image manipulation and duplication in scientific papers. Companies like **Proofig** and **ImageTwin** launched services specifically for journals to scan manuscripts for duplicated images, often using AI-based pattern recognition. Many major publishers, including Springer Nature and Elsevier, began deploying such tools. 

Despite these advances, paper retractions due to image manipulation continued at high rates. The blog *Retraction Watch* documented thousands of retractions annually by the late 2010s, with image duplication remaining a leading cause. High-profile cases continued to emerge regularly. For example, in 2021, MIT terminated a prominent cancer researcher after investigations found widespread image manipulation in numerous papers. In 2020, the University of Tokyo investigated over 40 papers from one researcher for image fabrication. Many institutions strengthened misconduct policies, but detection and enforcement remained uneven.

The promise of automated detection did materialize to some extent, but implementation varied widely among journals, with some adopting rigorous screening while others remained reactive. The broader concern about AI systems ingesting flawed literature proved somewhat prescient: as large language models trained on scientific corpora emerged in the 2020s, researchers raised concerns about potential contamination with retracted or fabricated studies. Several initiatives emerged to create "cleaned" scientific datasets with retractions flagged or removed, though comprehensive filtering remained challenging.

## 3. PREDICTIONS

• **Prediction**: That journal editors would adopt automated image-comparison software to detect duplication
  - **Outcome**: Mixed. Many major publishers did implement such tools by the late 2010s, but adoption was uneven across the thousands of journals. Some smaller publishers still relied on manual detection or post-publication whistleblowing.

• **Prediction**: That the scientific literature contained substantial fabricated data that would contaminate AI knowledge-extraction systems
  - **Outcome**: Partially accurate. Research in the 2020s showed that scientific datasets do contain retracted papers, though quantifying the impact remains difficult. Initiatives like Semantic Scholar began explicitly flagging retracted papers to prevent AI contamination.

• **Prediction**: That the University of Malaya would investigate the specific case mentioned
  - **Outcome**: Unknown. No public record of the outcome of that specific investigation is readily available in major retraction databases or news coverage.

## 4. INTEREST

Rating: **7/10**

The article identified a critical systemic problem in scientific publishing that remained highly relevant for years afterward, accurately predicting the need for automated detection and the risks of AI contamination. While focused on a specific case, it highlighted issues with lasting policy implications.

---


----
_model_params = {'model': 'nex-agi/deepseek-v3.1-nex-n1:free', 'input': '20161101-dupeless-needication.txt', 'reasoning': {'effort': 'high'}, 'text': {'verbosity': 'medium'}, 'prompt-template': 'prompt-template-2'}_