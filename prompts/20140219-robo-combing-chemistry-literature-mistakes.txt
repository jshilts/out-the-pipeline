Robo-Combing the Chemistry Literature For Mistakes
19 Feb 2014

This is a very timely post indeed (http://blogs.ch.cam.ac.uk/pmr/2014/02/18/machines-are-better-referees-than-humans-but-well-be-sued-if-we-use-them/) from Peter Murray-Rust. He's describing a system that his group has developed (ChemVisitor) to dig through the chemical literature looking for incorrect structures (and much more). 
 He shows examples from an open-access paper, in which one of the structures is in fact misdrawn. But how would Elsevier, Nature, the ACS, Wiley or the other big publishers take to having these things highlighted every day of the week. Not well: 
 So try it for yourself. Which compound is wrong? (*I* don’t know yet) How would you find out? Maybe you would go to Chemical Abstracts (ACS). Last time I looked it cost 6USD to look up a compound. That’s 50 dollars, just to check whether the literature is right. And you would be forbidden from publishing what you found there (ACS sent the lawyers to Wikipedia for publishing CAS registry numbers). What about Elsevier’s Reaxys? Almost certainly as bad. 
 But isn’t there an Open collection of molecules? Pubchem in the NIH? Yes, and ACS lobbied on Capitol Hill to have it shut down as it was “socialised science instead of the private sector”. They nearly won. (Henry Rzepa and I ran a campaign to highlight the issue). So yes, we can use Pubchem and we have and that’s how Andy’s software discovered the mistake. 
 This was the first diagram we analysed. Does that mean that every paper in the literature contains mistakes? 
 Almost certainly yes. 
 But they have been peer-reviewed. 
 Yes – and we wrote software (OSCAR) 10 years ago that could do the machine reviewing. And it showed mistakes in virtually every paper. 
 So we plan to do this for every new paper. It’s technically possible. But if we do it what will happen? 
 If I sign the Elsevier content-mining click-through (I won’t) then I agree not to disadvantage Elsevier’s products. And pointing out publicly that they are full of errors might just do that. And if I don’t?… 
 This comment (https://news.ycombinator.com/item?id=7262479) on Ycombinator is from someone who's seen some of the Murray-Rost group's software in action, and is very interesting indeed: 
 They can take an ancient paper with very low quality diagrams of complex chemical structures, parse the image into an open markup language and reconstruct the chemical formula and the correct image. Chemical symbols are just one of many plugins for their core software which interprets unstructured, information rich data like raster diagrams. They also have plugins for phylogenetic trees, plots, species names, gene names and reagents. You can develop plugins easily for whatever you want, and they're recruiting open source contributors (see https://solvers.io/projects/QADhJNcCkcKXfiCQ6, https://solvers.io/projects/4K3cvLEoHQqhhzBan). 
 As a side effect of how their software works, it can detect tiny suggestive imperfections in images that reveal scientific fraud. I was shown a demo where a trace from a mass spec (like this http://en.wikipedia.org/wiki/File:ObwiedniaPeptydu.gif) was analysed. As well as reading the data from the plot, it revealed a peak that had been covered up with a square - the author had deliberately obscured a peak in their data that was inconvenient. Scientific fraud. It's terrifying that they find this in most chemistry papers they analyse. 
 Peter's group can analyse thousands or hundreds of thousands of papers an hour, automatically detecting errors and fraud. . . 
 Unless I'm very much mistaken, we'll be hearing a lot more about this. It touches on the quality of the literature, the quality of the people writing the papers, and the business model(s) of the people publishing it all. And these are very, very relevant topics that are are getting more important all the time. . .